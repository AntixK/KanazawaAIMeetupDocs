{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "誤差関数\n",
    "\n",
    "<img src=\"loss_function.png\">\n",
    "\n",
    "学習する際は、分割された領域する際は、分割された領域で、\n",
    "- Pr(obj)・・・バウンディングボックスに物体が含まれる確率(0と1で表された行列　バウンディングボックスの中心がグリットセルに含まれている場合は1、それ以外は0)\n",
    "- IoU・・・予測されたバウンディングボックスと政界のバウンディングボックスの重なり具合\n",
    "\n",
    "を掛け算した式「q=Pr(Obj)*IoU」を、バウンディングボックスの信頼度として計算し、誤差関数に加える\n",
    "\n",
    "物体検出時には、\n",
    "- P(Class|Obj)・・・その領域がどのクラスに属している確率が高いかという予測と\n",
    "- q・・・バウンディングボックスの信頼度\n",
    "\n",
    "を掛け算した式「P(Class|Obj)*q」を使用して、同じ領域に複数のバウンディングボックスが出現しすぎないようにする\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- IoUはintersection over unionの略\n",
    "<img src=\"https://meideru.com/wp-content/uploads/2017/05/iou_value_1.png\">\n",
    "- 予測された複数のバウンディングボックスのうち、重なっている部分が大きい場合は一つに絞る。逆に重なっている部分が小さい、もしくは全く無いバウンディングボックスの場合は、消去せずに残す。\n",
    "- Non-Maximum Suppression(https://meideru.com/archives/3538)\n",
    "\n",
    "<img src=\"region.png\">\n",
    "\n",
    "- バウンディングボックスの信頼度を予測するものと、どのクラスに分類されているかを予測するネットワークがある。それら２つの意見を合算\n",
    "\n",
    "- SxS個のグリッドセル\n",
    "- 最終的な出力は各領域ごとにC個のクラス確率とB個のバウンディングボックスを予測する\n",
    "- バウンディングボックスは５つの要素からなる\n",
    "- 最終的な出力はS×S×(B∗5 + C)個のテンソルを出力 それぞれのグリッドセルに、バウンディングボックスに関する位置の情報が含まれている。\n",
    "\n",
    "<img src=\"yolo.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 参考文献\n",
    "github,11月2日参照\n",
    "https://github.com/hizhangp/yolo_tensorflow/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    def loss_layer(self, predicts, labels, scope='loss_layer'):\n",
    "        with tf.variable_scope(scope):\n",
    "            predict_classes = tf.reshape(\n",
    "                predicts[:, :self.boundary1],\n",
    "                [self.batch_size, self.cell_size, self.cell_size, self.num_class])\n",
    "            predict_scales = tf.reshape(\n",
    "                predicts[:, self.boundary1:self.boundary2],\n",
    "                [self.batch_size, self.cell_size, self.cell_size, self.boxes_per_cell])\n",
    "            predict_boxes = tf.reshape(\n",
    "                predicts[:, self.boundary2:],\n",
    "                [self.batch_size, self.cell_size, self.cell_size, self.boxes_per_cell, 4])\n",
    "\n",
    "            response = tf.reshape(\n",
    "                labels[..., 0],\n",
    "                [self.batch_size, self.cell_size, self.cell_size, 1])\n",
    "            boxes = tf.reshape(\n",
    "                labels[..., 1:5],\n",
    "                [self.batch_size, self.cell_size, self.cell_size, 1, 4])\n",
    "            boxes = tf.tile(\n",
    "                boxes, [1, 1, 1, self.boxes_per_cell, 1]) / self.image_size\n",
    "            classes = labels[..., 5:]\n",
    "\n",
    "            offset = tf.reshape(\n",
    "                tf.constant(self.offset, dtype=tf.float32),\n",
    "                [1, self.cell_size, self.cell_size, self.boxes_per_cell])\n",
    "            offset = tf.tile(offset, [self.batch_size, 1, 1, 1])\n",
    "            offset_tran = tf.transpose(offset, (0, 2, 1, 3))\n",
    "            predict_boxes_tran = tf.stack(\n",
    "                [(predict_boxes[..., 0] + offset) / self.cell_size,\n",
    "                 (predict_boxes[..., 1] + offset_tran) / self.cell_size,\n",
    "                 tf.square(predict_boxes[..., 2]),\n",
    "                 tf.square(predict_boxes[..., 3])], axis=-1)\n",
    "\n",
    "            iou_predict_truth = self.calc_iou(predict_boxes_tran, boxes)\n",
    "\n",
    "            # calculate I tensor [BATCH_SIZE, CELL_SIZE, CELL_SIZE, BOXES_PER_CELL]\n",
    "            #オブジェクトがあるところの領域をTrue(1)他を0として、マスクを作る。\n",
    "            object_mask = tf.reduce_max(iou_predict_truth, 3, keep_dims=True)\n",
    "            object_mask = tf.cast(\n",
    "                (iou_predict_truth >= object_mask), tf.float32) * response\n",
    "\n",
    "            # calculate no_I tensor [CELL_SIZE, CELL_SIZE, BOXES_PER_CELL]\n",
    "            #オブジェクトがないところの領域を1として、他を0として、マスクを作る。\n",
    "            noobject_mask = tf.ones_like(\n",
    "                object_mask, dtype=tf.float32) - object_mask\n",
    "\n",
    "            boxes_tran = tf.stack(\n",
    "                [boxes[..., 0] * self.cell_size - offset,\n",
    "                 boxes[..., 1] * self.cell_size - offset_tran,\n",
    "                 tf.sqrt(boxes[..., 2]),\n",
    "                 tf.sqrt(boxes[..., 3])], axis=-1)\n",
    "\n",
    "            # class_loss\n",
    "            class_delta = response * (predict_classes - classes)\n",
    "            class_loss = tf.reduce_mean(\n",
    "                tf.reduce_sum(tf.square(class_delta), axis=[1, 2, 3]),\n",
    "                name='class_loss') * self.class_scale\n",
    "\n",
    "            # object_loss\n",
    "            #object_mastで、考慮したいlossのみ抽出する。考慮しなくて良いlossは0を掛け算される。\n",
    "            #predict_scalesは\n",
    "            #[self.cell_size, self.cell_size, self.boxes_per_cell]の情報を持つ\n",
    "            #あらかじめトレーニングの際に計算されたiou値と、予測されたiou値の差分が誤差になる。\n",
    "            object_delta = object_mask * (predict_scales - iou_predict_truth)\n",
    "            object_loss = tf.reduce_mean(\n",
    "                tf.reduce_sum(tf.square(object_delta), axis=[1, 2, 3]),\n",
    "                name='object_loss') * self.object_scale\n",
    "\n",
    "            # noobject_loss\n",
    "            #オブジェクトがない領域に0の教師を割り当てて、(予測-0)^2の誤差を計算する。\n",
    "            #0の引き算の項は明示しなくても良いので、（予測）^2を誤差にしている。\n",
    "            #オブジェクトがないときは、iou値は0を出力しなければならないのに、0以上の実数値が出た場合は、\n",
    "            #lossになる\n",
    "            noobject_delta = noobject_mask * predict_scales\n",
    "            noobject_loss = tf.reduce_mean(\n",
    "                tf.reduce_sum(tf.square(noobject_delta), axis=[1, 2, 3]),\n",
    "                name='noobject_loss') * self.noobject_scale\n",
    "\n",
    "            # coord_loss\n",
    "            coord_mask = tf.expand_dims(object_mask, 4)\n",
    "            boxes_delta = coord_mask * (predict_boxes - boxes_tran)\n",
    "            coord_loss = tf.reduce_mean(\n",
    "                tf.reduce_sum(tf.square(boxes_delta), axis=[1, 2, 3, 4]),\n",
    "                name='coord_loss') * self.coord_scale\n",
    "\n",
    "            tf.losses.add_loss(class_loss)\n",
    "            tf.losses.add_loss(object_loss)\n",
    "            tf.losses.add_loss(noobject_loss)\n",
    "            tf.losses.add_loss(coord_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 推論するときのフロー\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def process_predicts(predicts):\n",
    "  p_classes = predicts[0, :, :, 0:20]\n",
    "  #Cはそれぞれのグリッドセルごとの、バウンディングボックスの中心座標の存在確率\n",
    "  #それぞれの要素が0~1の行列\n",
    "  C = predicts[0, :, :, 20:22]\n",
    "  \n",
    "  coordinate = predicts[0, :, :, 22:]\n",
    "  \n",
    "  #p_classesはそれぞれのグリッドセルが、どのクラスに分類される確率が高いかを表したもの。\n",
    "  #クラスの数だけレイヤーが存在する。\n",
    "  p_classes = np.reshape(p_classes, (7, 7, 1, 20))\n",
    "  C = np.reshape(C, (7, 7, 2, 1))\n",
    "\n",
    "  P = C * p_classes#バウンディングボックスの中心座標の存在確率*どのクラスに分類されるか\n",
    "\n",
    "  #print P[5,1, 0, :]\n",
    "\n",
    "  index = np.argmax(P)#クラスの分類確率とバウンディングボックスの存在確率maxの値のindexを取得\n",
    "\n",
    "  index = np.unravel_index(index, P.shape)#index取得\n",
    "\n",
    "  class_num = index[3]#クラスの分類確率とバウンディングボックスの存在確率maxの値が存在するクラスを検出クラスとする\n",
    "\n",
    "  coordinate = np.reshape(coordinate, (7, 7, 2, 4))\n",
    "\n",
    "  max_coordinate = coordinate[index[0], index[1], index[2], :]\n",
    "\n",
    "  xcenter = max_coordinate[0]\n",
    "  ycenter = max_coordinate[1]\n",
    "  w = max_coordinate[2]\n",
    "  h = max_coordinate[3]\n",
    "\n",
    "  xcenter = (index[1] + xcenter) * (448/7.0)\n",
    "  ycenter = (index[0] + ycenter) * (448/7.0)\n",
    "\n",
    "  w = w * 448\n",
    "  h = h * 448\n",
    "\n",
    "  xmin = xcenter - w/2.0\n",
    "  ymin = ycenter - h/2.0\n",
    "\n",
    "  xmax = xmin + w\n",
    "  ymax = ymin + h\n",
    "\n",
    "  return xmin, ymin, xmax, ymax, class_num\n",
    " ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## わからなかったこと\n",
    "- 大きな物体を検出するときは、バウンディングボックスをどのように描き連結するか、また、なぜそれぞれのグリッドごとにバウンディングボックスを複数用意するのか==>width,heightと中心座標を出力するので、そこから自由にバウンディングボックスを描ける\n",
    "- 推論時のフロー"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 参考文献\n",
    "本資料に使われている文献・図は非営利の勉強会などの教育目的に引用されており、引用した図や資料などの著作権は著作者に帰属します。\n",
    "- https://www.slideshare.net/ssuser07aa33/introduction-to-yolo-detection-model\n",
    "- https://www.slideshare.net/DeepLearningJP2016/dl-reading-paper20170804pdf\n",
    "- https://arxiv.org/abs/1506.02640 (You Only Look Once: Unified, Real-Time Object Detection,参照日　2018/11/3)\n",
    "- https://www.slideshare.net/ssuser07aa33/introduction-to-yolo-detection-model\n",
    "- https://github.com/llSourcell/YOLO_Object_Detection\n",
    "- https://github.com/hizhangp/yolo_tensorflow/\n",
    "- https://github.com/nilboy/tensorflow-yolo/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [chips]",
   "language": "python",
   "name": "Python [chips]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
