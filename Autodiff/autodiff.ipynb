{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kanazawa AI Meetup, 2018\n",
    "\n",
    "## Automatic Differentiation Tutorial\n",
    "- Anand Krish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "\n",
    "# Database for precomputed derivatives for elementary functions \n",
    "# (Add your own gradients here)\n",
    "G = {\n",
    "     \"add\":lambda a,b: a+b,\n",
    "     \"sub\":lambda a,b: a-b,\n",
    "     \"mul\":lambda a,b: a*b,\n",
    "     \"square\":lambda  a: a**2,\n",
    "     \"log\":lambda a:np.log(a),\n",
    "     \"sin\":lambda a:np.sin(a),\n",
    "     }\n",
    "\n",
    "DG = {\n",
    "    \"add\":[(lambda a,b: 1),(lambda a,b: 1)],\n",
    "    \"sub\":[(lambda a,b: 1),(lambda a,b: -1)],\n",
    "    \"mul\":[(lambda a,b: b),(lambda a,b: a)],\n",
    "    \"square\":[(lambda  a: 2*a)],\n",
    "    \"log\":[(lambda  a: 1/a)],\n",
    "    \"sin\":[(lambda  a: np.cos(a))],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reverse Accumulation Code\n",
    "# Forward Pass\n",
    "def eval(f,val):\n",
    "    for t in f:\n",
    "        op = G[t[1]]    # Get the lambda function for the corresponding function name\n",
    "        var = list(map(val.get, t[2])) # Get the values of variables from the dict\n",
    "        val[t[0]] = op(*var)  # Obtain the result of the function for the list of values\n",
    "    return val[\"f\"]     # Return the final value\n",
    "\n",
    "# Reverse pass (back propagate the gradients from the output to the input)\n",
    "def rev_acc(f,val):\n",
    "    delta[\"f\"] = 1 # Output jitter\n",
    "    for t in reversed(f): # Scan from the output to the input\n",
    "        var = list(map(val.get, t[2])) \n",
    "        for i in range(len(t[2])): # Perform backprop for each variable in the function\n",
    "            op = DG[t[1]][i]   # Obtain the precomputer gradient\n",
    "            delta[t[2][i]] += delta[t[0]]*op(*var) # standard error update rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward Pass for f\n",
      "{\n",
      "    \"x1\": 3,\n",
      "    \"x2\": 7,\n",
      "    \"z1\": 6,\n",
      "    \"z2\": 42,\n",
      "    \"z3\": 49,\n",
      "    \"f\": 2401\n",
      "}\n",
      "Reverse Pass for f\n",
      "{\n",
      "    \"x1\": 1372,\n",
      "    \"x2\": 686,\n",
      "    \"z1\": 686,\n",
      "    \"z2\": 98,\n",
      "    \"z3\": 98,\n",
      "    \"f\": 1\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# f = (2x1*x2 + x2)^2\n",
    "val = {\"x1\":3, \"x2\":7}\n",
    "delta = {\"x1\":0,\"x2\":0}\n",
    "inter_val = {\"z1\":0,\"z2\":0,\"z3\":0,\"f\":0}\n",
    "f = [(\"z1\",\"add\", [\"x1\",\"x1\"]),\n",
    "     (\"z2\",\"mul\", [\"x2\",\"z1\"]),\n",
    "     (\"z3\", \"add\", [\"x2\", \"z2\"]),\n",
    "     (\"f\", \"square\", [\"z3\"])]\n",
    "\n",
    "\n",
    "val = {**val, **inter_val}\n",
    "delta = {**delta, **inter_val}\n",
    "\n",
    "## One forward pass and one reverse pass\n",
    "eval(f,val)\n",
    "# Ensure whether all the variables are computed\n",
    "print(\"Forward Pass for f\")\n",
    "print(json.dumps(val, indent=4))\n",
    "# Perform Reverse Mode Autodiff\n",
    "rev_acc(f,val)\n",
    "print(\"Reverse Pass for f\")\n",
    "print(json.dumps(delta, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward Pass for f\n",
      "{\n",
      "    \"x1\": 2,\n",
      "    \"x2\": 5,\n",
      "    \"z1\": 0.6931471805599453,\n",
      "    \"z2\": 10,\n",
      "    \"z3\": -0.9589242746631385,\n",
      "    \"z4\": 10.693147180559945,\n",
      "    \"f\": 11.652071455223084\n",
      "}\n",
      "Reverse Pass for f\n",
      "{\n",
      "    \"x1\": 5.5,\n",
      "    \"x2\": 1.7163378145367738,\n",
      "    \"z1\": 1,\n",
      "    \"z2\": 1,\n",
      "    \"z3\": -1,\n",
      "    \"z4\": 1,\n",
      "    \"f\": 1\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# f = log(x1) +x1x2 - sin(x2)\n",
    "val = {\"x1\":2, \"x2\":5}\n",
    "delta = {\"x1\":0,\"x2\":0}\n",
    "inter_val = {\"z1\":0,\"z2\":0,\"z3\":0,\"z4\":0,\"f\":0}\n",
    "f = [(\"z1\",\"log\", [\"x1\"]),\n",
    "     (\"z2\",\"mul\", [\"x2\",\"x1\"]),\n",
    "     (\"z3\", \"sin\", [\"x2\"]),\n",
    "     (\"z4\", \"add\", [\"z1\",\"z2\"]),\n",
    "     (\"f\", \"sub\", [\"z4\",\"z3\"])]\n",
    "\n",
    "val = {**val, **inter_val}\n",
    "delta = {**delta, **inter_val}\n",
    "\n",
    "## One forward pass and one reverse pass\n",
    "eval(f,val)\n",
    "# Ensure whether all the variables are computed\n",
    "print(\"Forward Pass for f\")\n",
    "print(json.dumps(val, indent=4))\n",
    "# Perform Reverse Mode Autodiff\n",
    "rev_acc(f,val)\n",
    "print(\"Reverse Pass for f\")\n",
    "print(json.dumps(delta, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward Pass for f1\n",
      "{\n",
      "    \"x1\": 3,\n",
      "    \"z2\": 0,\n",
      "    \"f\": 9\n",
      "}\n",
      "Reverse Pass for f1\n",
      "{\n",
      "    \"x1\": 6,\n",
      "    \"z2\": 0,\n",
      "    \"f\": 1\n",
      "}\n",
      "-----------------------------------------\n",
      "Forward Pass for f2\n",
      "{\n",
      "    \"x1\": 3,\n",
      "    \"z2\": 6,\n",
      "    \"f\": 1.791759469228055\n",
      "}\n",
      "Reverse Pass for f2\n",
      "{\n",
      "    \"x1\": 6.333333333333334,\n",
      "    \"z2\": 0.16666666666666666,\n",
      "    \"f\": 1\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# f = [x^2, log(2x)]\n",
    "val = {\"x1\":3}\n",
    "delta = {\"x1\":0}\n",
    "inter_val = {\"z2\":0,\"f\":0}\n",
    "f1 = [(\"f\", \"square\", [\"x1\"])]\n",
    "f2 = [(\"z2\",\"add\", [\"x1\",\"x1\"]),\n",
    "     (\"f\", \"log\", [\"z2\"])]\n",
    "\n",
    "val = {**val, **inter_val}\n",
    "delta = {**delta, **inter_val}\n",
    "\n",
    "## Two forward passes and two reverse passes\n",
    "# Reverse accumulation w.r.t. f1\n",
    "eval(f1,val)\n",
    "# Ensure whether all the variables are computed\n",
    "print(\"Forward Pass for f1\")\n",
    "print(json.dumps(val, indent=4))\n",
    "# Perform Reverse Mode Autodiff\n",
    "rev_acc(f1,val)\n",
    "print(\"Reverse Pass for f1\")\n",
    "print(json.dumps(delta, indent=4))\n",
    "print(\"-----------------------------------------\")\n",
    "# Reverse accumulation w.r.t. f2\n",
    "eval(f2,val)\n",
    "# Ensure whether all the variables are computed\n",
    "print(\"Forward Pass for f2\")\n",
    "print(json.dumps(val, indent=4))\n",
    "# Perform Reverse Mode Autodiff\n",
    "rev_acc(f2,val)\n",
    "print(\"Reverse Pass for f2\")\n",
    "print(json.dumps(delta, indent=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
